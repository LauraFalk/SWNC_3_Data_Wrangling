---
title: "Data Wrangling Main"
author: "Laura Palacios"
date: '2022-12-23'
output: html_document
---

```{r setup, include=FALSE}
# Call the required libraries
library(csv)
library(janitor)
library(knitr)
library(tidyverse)

# This is auto-populated in RMD creation and used for formatting purposes.
opts_chunk$set(echo = TRUE)
```

This r teaching session will introduce data wrangling tasks which commonly occur in National Park Service activities.

We will cover:

0. Awards and Accolades!
1. Review of GitHub - retrieving this document from space!
2. Importing a CSV as a data frame
3. Viewing the file
4. Data clean up
  - Remove rows with missing data
  - Filter data
  - Change column names
  - Change column layout
  - Convert column data type
  

## 0. Awards and Accolades!
  ![](images/GoldenBison.png){width=250px, align=center} </br>
  Congratulations to Rachel, Kara, Carolyn, Rebecca, Ann, Jessica, Helen, and Anna: our Golden Bison recipients. These individuals all successfully competed the second SWNC training on Github.
  
## 1. GitHub Review
1. Send Laura your GitHub username so that she can give you editing access to the repo.

    *Note for recording listeners*: You can still complete this training without repo editing access. If you prefer, complete only GitHub Review steps 4 and 5 to download a local, editable copy of the training to your machine. The only difference is that you will not be able to push your completed training back onto GitHub.

2. Go to the location of the repository at [https://github.com/palacila/SWNC_3_Data_Wrangling](https://github.com/palacila/SWNC_3_Data_Wrangling). 

3. Click on the **main dropdown** in the upper left, and begin typing your name separated by underscores. Once complete, click on **'Create branch:*your name* from main'**. This will create your branch! 

  ![](images/CreateBranch.png){width=350px, align=center} </br>

4. Clone the Repo
Click on **code** in the upper right, and copy the HTTPS url provided. 

  ![](images/CloneRepo.png){width=250px, align=center} </br>

5. Open R Studio. Go to **File>NewProject>VersionControl>Git** . Paste the repository URL. Information and download location should auto-populate. Click **Create Project**.

6. Switch to your branch in R studio. 

    Navigate to the Git Panel (upper right) in RStudio. If it is not there, you can go to **View >ShowGit** to view it.
Click the drop down menu in the upper right and select your branch name to switch to your branch!  

  ![](images/SwitchBranch.png){width=500px} </br>

7. Open the RMD file titled **Data_Wrangling_Learner.RMD** by using the file tab in the lower right corner of R studio.

    We will be filling in the blanks of this document, then pushing the completed RMD files back onto GitHub. Please note that **Data_Wrangling_Main.RMD** is a completed copy of this lesson plan which can be used as reference. 
    
    Please fill in the author section of the header now.


## 2. Importing a CSV as a data frame

**To do** If you do not have csv installed, use **install.packages("csv")** in the console to install. 

**To do** Load the library by using library()
```{r}
# Do not fear the notifications. This is expected.
library(csv)
```
    
Import the file

What file types can be imported? Most file types will have their own library to make it easy to bring the data into R studio. Unsure what to use? Google "r read in file-type" to find the appropriate library.


We will be using a CSV file for this training, found here: [Groundhog data](https://www.kaggle.com/datasets/groundhogclub/groundhog-day). The file has already been placed into the data folder of this repo.


**To do** Use the read.csv() function to read in the csv from the data folder. Use <- to assign it to the variable name groundhog_raw
```{r}
# Import the dataset
groundhog_raw <- read.csv("data/Groundhog_Data.csv")
```

## 3. View the file

**To do** The data you just imported will appear in the environment (top right corner). Single click the title to open a new tab and view the data table. Use the arrows next to the column headers to sort and view the data in different ways.


There are also quick functions which can be used to quickly assess our imported data without viewing the whole file.

Head() will show the first rows of data.
**To do** Run the code chunk below by clicking on the green arrow.
```{r}
# First rows of groundhog_raw, default is 5 rows
head(groundhog_raw)
```

**To do** Run the code chunk below by clicking on the green arrow.
```{r}
# You can add more arguments to the function. The inclusion of the integer "4" will show the first 4.
head(groundhog_raw, 4)
```


Similarly, tail() can be used to see the end of the imported dataset.

**To do** Use the tail() function to view the last 3 rows of groundhog_raw.
```{r}
# View the last three rows of groundhog_raw
tail(groundhog_raw,3)
```


We can also look at summary statistics to gain more understanding of the dataset we've imported. Numeric data will show calculated statistics and missing data. Other data types will be noted with only their type.

**To do** Use the summary() function on groundhog_raw.
```{r}
# View the summary statistics of groundhog_raw
summary(groundhog_raw)
```


The last task we'll do is count the number of rows and columns in our current dataframe.

*To do* Run nrow() and ncol().
```{r}
# The output should match the dataframe details in your environment (132 obs.)
nrow(groundhog_raw)

# The output should match the dataframe details in  your environment(10 variables)
ncol(groundhog_raw)
```

## 4.The Question!

**Did Punxsutawney Phil predict an early spring (no shadow) correctly (February average temperature above freezing) in Pennsylvania from 1900-2000? **

Below is a visualization of the data we are interested in. Stay tuned for further training if you want to learn how to make pretty graphs! 

Notice that there are still some problems in the raw data (such as missing records) which should be addressed. 

![](images/Groundhog_Raw_Graph.png){width=500px, align=center} </br>


Remember the question:
**Did Punxsutawney Phil predict an early spring correctly in Pennsylvania from 1900-2000? **

What we need to do: 

a. Tidy the column names

b. Clean up missing data

c. Phil's prediction: Filter for predict early spring (Punxsutawney Phil = No Shadow)

d. Was he right: Filter for temperature above freezing (February Average Temperature Pennsylvania > 32)

e. Time frame: Convert to numeric and filter year range (year>1900 and year < 2000)

## 5. Data Clean-up

### a. Tidy column names
We sometimes import column names which are difficult to work with or do not adequately reference the data. Lets look at our imported dataset.

**To Do** Print out the current column names of groundhog_raw using the colnames() function.
```{r}
colnames(groundhog_raw)
```


Column names can be changed in numerous ways. This course will use the tidyverse library package.

**To do** If you do not have tidyverse installed, use **install.packages("tidyverse")** in the console to install. 

**To do** Load the library by using library()
```{r}
# Do not fear the notifications, there will be many. This is expected.
library(tidyverse)
```

When using tidyverse, it is important to understand the pipeline (%>%). A pipeline denote a continuous chain of functions (output becomes the input of the following function).

While not necessary, the pipeline is strongly recommended as a tool to streamline your code. Below is an example which includes the same task both with and without a pipeline.

![](images/Groundhog_Pipeline.png){align=center} </br>
In a code block structure these two processes would look like:
*With Pipeline*
groundhog_final <- groundhog %>%
 eyes() %>%
 nose() %>%
 mouth()

*Without Pipeline*
groundhog_eyes <- eyes(groundhog)
groundhog_nose <- nose(groundhog_eyes)
groundhog_final <- mouth(groundhog_nose)

The pipeline allows use to easily visualize the processes that are occurring without needing to create a new object each time.


**To do** Create a new dataframe called groundhog_renamed. Pipeline from groundhog_raw. Use the rename function to rename "February.Average.Temperature..Midwest." to Feb_Mid. 
*hint* Remember the help function of R studio will list required inputs and the format they should be in.
```{r}
# New Variable <- Old Variable pipleline
groundhog_renamed <- groundhog_raw %>%
  #rename(new name = old name)
  rename(Feb_Mid = February.Average.Temperature..Midwest.,) 
```

Below is an example of renaming using index location (column number) rather than column name. While this can be speedy and efficient, it will break if you alter the column order. It is not often advised for continuous processing tasks.
```{r}
# New Variable <- Old Variable pipleline
groundhog_renamed <- groundhog_renamed %>%
  # rename function using column index
  rename(Feb_Average = 3,
    Mar_Average = 7)
```

There are also many options for batch renaming, which can use pattern-matching to rename columns. While this can be more complicated, it can be a great time-saver when working with multiple imported files. 

This is an example of a batch rename based on pattern matching. While it looks complicated, it can simply be copy/pasted into your own code, just change the inputs to what you need!
```{r}
# Dataframe pipeline
groundhog_renamed <- groundhog_renamed %>%
  # Call rename_with. Use the function (copied from online) to substitute Feb_ for the longer string.
  rename_with(function(x){gsub("February.Average.Temperature..","Feb_",x)})
```

**To do** Copy/paste the above code, alter the text to complete the same process for March.
```{r}
# March renaming function
groundhog_renamed <- groundhog_renamed %>%
  rename_with(function(x){gsub("March.Average.Temperature..","Mar_",x)})
```



The janitor library can also help with built-in column name cleanup processes. It will remove any any characters that are not lower-case letters, underscores, or numbers. It is commonly used in conjunction with the tidyverse library, but must be loaded separately.

**To do** If you do not have janitor installed, use **install.packages("janitor")** in the console to install. 

**To do** Load the library by using library()
```{r}
# Do not fear the install notifications, there will be many. This is expected.
library(janitor)
```

In our dataset, the janitor library will get rid of the periods and standardize our capitalization.
**To do** Begin with *groundhog_renamed <-* to replace our current working dataset. Create a pipeline which calls the function clean_names() on groundhog_renamed.
```{r}
# Janitor does the work for us.
groundhog_renamed <- groundhog_renamed %>%
  clean_names()
```


### b. Clean up missing data.

There are many different functions and libraries that can be used for data cleanup. Again, this training will focus on tidyverse. 


The first thing we will do is remove the rows which contain NAs. Luckily, there's a function for this. 

**To do** From groundhog_raw, pipeline ot the tidyverse function remove_na().
```{r}
# Notice that the output has 9 fewer rows (123 obs.)
groundhog_raw %>%
  drop_na()
```

**To do** View the new dataframe and sort by the column Punxsutawney.Phil.  Notice there is an empty string for year 1901-2000. This was not dropped in the previous code block due to the character (not numeric) data type. 


**To do** Create a new output called groundhog_clean. Using a tidyverse pipeline from groundhog_raw, replace the null character values with na_if(""). Then, pipeline drop_na() to remove ALL missing data.
```{r}
# new_dataframe <- raw_dataframe %>% replace Null with NA %>% remove all NAs
# Output should contain 122 rows.
groundhog_clean <- groundhog_raw %>%
  na_if("") %>%
  drop_na()
```

Note: We have only covered missing row removal in this course. When dealing with large-scale numeric data, there are a number of other options which may be employed.

But there is still a problem with the data!
![](images/Groundhog_Raw_Graph.png){width=500px, align=center} </br>

From the graph of the raw data, we know there are instances where Punxsutawney Phil has "No Record". For the purposes of answering our question we also want to remove this data.
**To do** Take a look at the current unique values by running the code chunk below.
```{r}
# Focus on Punxsutawney Phil outcome
groundhog_clean$Punxsutawney.Phil %>%
  # find unique values
  unique()

```

```{r}
# Data pipeline
groundhog_clean <- groundhog_clean %>%
  # Filter out the data we don't want using !=
  filter(Punxsutawney.Phil != "No Record")
```

### b. Filter for predict early spring

**To do** Use the filter function for Punxsutawney.Phil = No Shadow"
```{r}
# Data pipeline
groundhog_clean <- groundhog_clean %>%
  # Filter out the data we don't want using !=
  filter(Punxsutawney.Phil != "No Record")
```


### d. Change column layout

Often times, we want to manipulate our tables so that the columns are in a logical order. There are many ways to accomplish this task. 

An easy way to move specific columns is to use the tidyverse relocate function. We can list the column names that we want, and they will be placed in order at the front of the data frame.
```{r}
# Create a new dataframe using a pipeline from groundhog_renamed
groundhog_layout <- groundhog_renamed %>% 
  # Relocate the average columns to the front
  relocate(mar_average,feb_average)
```

**To Do**
```{r}

```

### e. Convert column to appropriate type
make this numeric LAURA

## 3.The Answer!

```{r}
# Raw Data pipeline
groundhog_layout %>%
  # Filter out full and partial shadow predictions (not part of the question)
  filter(punxsutawney_phil != "Full Shadow", punxsutawney_phil != "Partial Shadow") %>%
  # Make a plot of the data. 
  ggplot(aes(y = year, x = feb_pennsylvania, fill = punxsutawney_phil)) + 
  geom_col()
```
Lets just see if the temperature is above 32. 

**To do** The full code block has been copy/pasted from above. Add a filter which grabs only feb_average values above 32 degrees. Remember to add a pipeline.

```{r}
# Raw Data pipeline
groundhog_layout %>%
  # Filter out full and partial shadow predictions (not part of the question)
  filter(punxsutawney_phil != "Full Shadow", punxsutawney_phil != "Partial Shadow") %>%
  # Additional Filter - don't forget the %>%
  filter(feb_pennsylvania >32) %>%
  # Make a plot of the data. 
  ggplot(aes(y = year, x = feb_pennsylvania, fill = punxsutawney_phil)) + 
  geom_col()
```




